{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e7b9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Main_Page\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    header_tags = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
    "\n",
    "    header_text = [tag.text for tag in header_tags]\n",
    "\n",
    "    df = pd.DataFrame(header_text, columns=[\"Header Text\"])\n",
    "\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07a2b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://presidentofindia.nic.in/former-presidents.htm\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    table = soup.find(\"table\")\n",
    "\n",
    "    names = []\n",
    "    terms_of_office = []\n",
    "\n",
    "    for row in table.find_all(\"tr\")[1:]:  \n",
    "        columns = row.find_all(\"td\")\n",
    "        name = columns[0].text.strip()\n",
    "        term_of_office = columns[1].text.strip()\n",
    "        names.append(name)\n",
    "        terms_of_office.append(term_of_office)\n",
    "\n",
    "    data = {\"Name\": names, \"Term of Office\": terms_of_office}\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26656da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_and_create_dataframe(url):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        headlines = []\n",
    "        times = []\n",
    "        news_links = []\n",
    "\n",
    "        news_items = soup.find_all('div', class_='Card')\n",
    "        for item in news_items:\n",
    "            headline = item.find('h3', class_='Card-title').text.strip()\n",
    "            time = item.find('time', class_='Card-time').text.strip()\n",
    "            news_link = item.find('a', class_='Card-hed').get('href')\n",
    "\n",
    "            headlines.append(headline)\n",
    "            times.append(time)\n",
    "            news_links.append(news_link)\n",
    "\n",
    "        data = {\n",
    "            'Headline': headlines,\n",
    "            'Time': times,\n",
    "            'News Link': news_links\n",
    "        }\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "cnbc_world_url = 'https://www.cnbc.com/world/?region=world'\n",
    "\n",
    "cnbc_world_df = scrape_and_create_dataframe(cnbc_world_url)\n",
    "\n",
    "if cnbc_world_df is not None:\n",
    "    print(\"CNBC World News:\")\n",
    "    print(cnbc_world_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c524511a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_and_create_dataframe(url):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        paper_titles = []\n",
    "        authors = []\n",
    "        published_dates = []\n",
    "        paper_urls = []\n",
    "\n",
    "        article_items = soup.find_all('div', class_='article-content')\n",
    "\n",
    "        for item in article_items:\n",
    "            title = item.find('a', class_='anchor-text').text.strip()\n",
    "            author = item.find('span', class_='js-article-authors').text.strip()\n",
    "            date = item.find('span', class_='js-article-date').text.strip()\n",
    "            url = item.find('a', class_='anchor-text').get('href')\n",
    "\n",
    "            paper_titles.append(title)\n",
    "            authors.append(author)\n",
    "            published_dates.append(date)\n",
    "            paper_urls.append(url)\n",
    "\n",
    "        data = {\n",
    "            'Paper Title': paper_titles,\n",
    "            'Authors': authors,\n",
    "            'Published Date': published_dates,\n",
    "            'Paper URL': paper_urls\n",
    "        }\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "elsevier_url = 'https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles'\n",
    "\n",
    "elsevier_df = scrape_and_create_dataframe(elsevier_url)\n",
    "\n",
    "if elsevier_df is not None:\n",
    "    print(\"Most Downloaded Articles in Artificial Intelligence:\")\n",
    "    print(elsevier_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6131c22d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733d1bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
